{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOSxpZCr9W9ISagywu8EPZa"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBGbBINorwgA",
        "outputId": "108e96be-f82e-4e36-ad13-586e24db8c51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28, 1) float32 (10000, 28, 28, 1) float32\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as np\n",
        "\n",
        "(X_train, _), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "def preprocess_data(dataset):\n",
        "    dataset = dataset.astype('float32') / 255.0\n",
        "    dataset = np.expand_dims(dataset, axis=-1)\n",
        "    return dataset\n",
        "\n",
        "X_train = preprocess_data(X_train)\n",
        "X_test = preprocess_data(X_test)\n",
        "\n",
        "print(X_train.shape, X_train.dtype, X_test.shape, X_test.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# VAE Encoder Model\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def vae_encoder(latent_dim=2, shape=(28,28,1)):\n",
        "    inputs = layers.Input(shape=shape)\n",
        "    x = layers.Conv2D(32, 3, strides=2, activation='relu', padding='same')(inputs)\n",
        "    x = layers.Conv2D(64, 3, strides=2, activation='relu', padding='same')(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(16, activation='relu')(x)\n",
        "\n",
        "    # 잠재 변수의 평균과 로그 분산\n",
        "    z_mean = layers.Dense(latent_dim)(x)\n",
        "    z_log_var = layers.Dense(latent_dim)(x)\n",
        "\n",
        "    model = Model(inputs, [z_mean, z_log_var], name='encoder')\n",
        "    return model"
      ],
      "metadata": {
        "id": "KdPgqzhvw1Km"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VAE Decoder Model\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def vae_decoder(latent_dim=2):\n",
        "    latent_inputs = layers.Input(shape=(latent_dim,))\n",
        "    x = layers.Dense(7*7*64, activation='relu')(latent_inputs)\n",
        "\n",
        "    x = layers.Reshape(target_shape=(7,7,64))(x)\n",
        "    x = layers.Conv2DTranspose(64, 3, strides=2, activation='relu', padding='same')(x)\n",
        "\n",
        "    x = layers.Conv2DTranspose(32, 3, strides=2, activation='relu', padding='same')(x)\n",
        "\n",
        "    outputs = layers.Conv2DTranspose(1, 3, activation='sigmoid', padding='same')(x)\n",
        "\n",
        "    model = Model(latent_inputs, outputs, name='decoder')\n",
        "    return model"
      ],
      "metadata": {
        "id": "0MNl8tz-w1YL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def sampling(z_mean, z_log_var):\n",
        "    batch = tf.shape(z_mean)[0]\n",
        "    dim = tf.shape(z_mean)[1]\n",
        "    epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
        "    return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
      ],
      "metadata": {
        "id": "-2VooN9Kw1rx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VAE 모델 정으\n",
        "latent_dim = 2\n",
        "encoder = vae_encoder(latent_dim=latent_dim)\n",
        "decoder = vae_decoder(latent_dim=latent_dim)\n",
        "\n",
        "inputs = layers.Input(shape=(28,28,1))\n",
        "z_mean, z_log_var = encoder(inputs)\n",
        "z = sampling(z_mean, z_log_var)\n",
        "outputs = decoder(z)\n",
        "\n",
        "vae_model = Model(inputs, outputs)\n",
        "vae_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rqVdiHw3ICB",
        "outputId": "cd9b03a7-c412-4e95-8989-f6e7cbfa5fdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)        [(None, 28, 28, 1)]          0         []                            \n",
            "                                                                                                  \n",
            " encoder (Functional)        [(None, 2),                  69076     ['input_3[0][0]']             \n",
            "                              (None, 2)]                                                          \n",
            "                                                                                                  \n",
            " tf.compat.v1.shape (TFOpLa  (2,)                         0         ['encoder[0][0]']             \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.compat.v1.shape_1 (TFOp  (2,)                         0         ['encoder[0][0]']             \n",
            " Lambda)                                                                                          \n",
            "                                                                                                  \n",
            " tf.math.multiply (TFOpLamb  (None, 2)                    0         ['encoder[0][1]']             \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (  ()                           0         ['tf.compat.v1.shape[0][0]']  \n",
            " SlicingOpLambda)                                                                                 \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_1  ()                           0         ['tf.compat.v1.shape_1[0][0]']\n",
            "  (SlicingOpLambda)                                                                               \n",
            "                                                                                                  \n",
            " tf.math.exp (TFOpLambda)    (None, 2)                    0         ['tf.math.multiply[0][0]']    \n",
            "                                                                                                  \n",
            " tf.random.normal (TFOpLamb  (None, 2)                    0         ['tf.__operators__.getitem[0][\n",
            " da)                                                                0]',                          \n",
            "                                                                     'tf.__operators__.getitem_1[0\n",
            "                                                                    ][0]']                        \n",
            "                                                                                                  \n",
            " tf.math.multiply_1 (TFOpLa  (None, 2)                    0         ['tf.math.exp[0][0]',         \n",
            " mbda)                                                               'tf.random.normal[0][0]']    \n",
            "                                                                                                  \n",
            " tf.__operators__.add (TFOp  (None, 2)                    0         ['encoder[0][0]',             \n",
            " Lambda)                                                             'tf.math.multiply_1[0][0]']  \n",
            "                                                                                                  \n",
            " decoder (Functional)        (None, 28, 28, 1)            65089     ['tf.__operators__.add[0][0]']\n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 134165 (524.08 KB)\n",
            "Trainable params: 134165 (524.08 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 손실함수 정의\n",
        "from tensorflow.keras.losses import mse\n",
        "\n",
        "# 재구성 손실 + KL 손실\n",
        "def vae_loss(inputs, outputs, z_mean, z_log_var):\n",
        "    # 재구성 손실\n",
        "    reconstruction_loss = mse(tf.keras.backend.flatten(inputs), tf.keras.backend.flatten(outputs))\n",
        "    reconstruction_loss *= 28 * 28 # 원래 이미지 크기가 반영되도록 이미지 화소의 개수만큼 곱해준다.\n",
        "\n",
        "    # KL 발산 손실(Kullback-Leibler divergence)\n",
        "    kl_loss = 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var) # KL 로스 수식을 구현\n",
        "    kl_loss = tf.reduce_sum(kl_loss, axis=-1) # 각 차원에 대한 합\n",
        "    kl_loss *= -0.5 # 부호를 맞추기 위해서 조정, KL 발산 조정\n",
        "\n",
        "    # 전체 손실\n",
        "    total_loss = tf.reduce_mean(reconstruction_loss + kl_loss) # 최종 손실 계산\n",
        "    return total_loss"
      ],
      "metadata": {
        "id": "7T1SGrgF3bTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 컴파일 및 학습\n",
        "vae_model.add_loss(vae_loss(inputs, outputs, z_mean, z_log_var))\n",
        "vae_model.compile(optimizer='adam')\n",
        "\n",
        "vae_model.fit(X_train, epochs=50, batch_size=128, validation_data=(X_test, None))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "id": "jRoumTLs3bhY",
        "outputId": "46a8dbce-7743-4f53-df0b-4b9df341dab8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "unhashable type: 'DictWrapper'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-a72cb01acff6>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 모델 컴파일 및 학습\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvae_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvae_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_log_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mvae_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvae_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\u001b[0m in \u001b[0;36madd_loss\u001b[0;34m(self, losses, **kwargs)\u001b[0m\n\u001b[1;32m   1553\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msymbolic_loss\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msymbolic_losses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_is_graph_network\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1555\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_network_add_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1556\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1557\u001b[0m                 \u001b[0;31m# Possible a loss was added in a Layer's `build`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/functional.py\u001b[0m in \u001b[0;36m_graph_network_add_loss\u001b[0;34m(self, symbolic_loss)\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0mnew_nodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madd_loss_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minbound_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m         \u001b[0mnew_layers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madd_loss_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insert_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_graph_network_add_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/functional.py\u001b[0m in \u001b[0;36m_insert_layers\u001b[0;34m(self, layers, relevant_nodes)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0;31m# Insert layers and update other layer attrs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 953\u001b[0;31m         \u001b[0mlayer_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_tracked_trackables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    954\u001b[0m         \u001b[0mdeferred_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/trackable/data_structures.py\u001b[0m in \u001b[0;36m__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 953\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unhashable type: 'DictWrapper'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    954\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'DictWrapper'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 저장하기\n",
        "model.save(\"vae.keras\")"
      ],
      "metadata": {
        "id": "jlRs7WcF4YxE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 불러오기\n",
        "vae_model.load_weights(\"vae.keras\")"
      ],
      "metadata": {
        "id": "mE8ZmAg94UHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 잠재 벡터를 이용한 이미지 생성\n",
        "digit = decoder.predict([[0, 0]])\n",
        "print(digit.shape)"
      ],
      "metadata": {
        "id": "GOsd2f_44gKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 시각화\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(3, 3))\n",
        "plt.imshow(digit[0,...], cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SnMJnDJV4gv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트\n",
        "z_test_mean, z_test_log_var = np.array(encoder.predict(X_test[:16, ...]))\n",
        "digits = decoder.predict(sampling(z_test_mean, z_test_log_var))\n",
        "\n",
        "plt.figure(figsize=(2,2))\n",
        "for i in range(16):\n",
        "    plt.subplot(4,4,i+1)\n",
        "    plt.imshow(digits[i,...], cmap='gray')\n",
        "    plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "print(y_test[:16])"
      ],
      "metadata": {
        "id": "2IlC2BXI4xJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test_latent1, x_test_latent2 = np.array(encoder.predict(X_test))\n",
        "x_test_mean, x_test_log_var = x_test_latent1[:,0], x_test_latent1[:,1]"
      ],
      "metadata": {
        "id": "9ePkOg5x5FKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 잠재벡터 확인\n",
        "x = z_test_mean[:, 0]\n",
        "y = z_test_mean[:, 1]\n",
        "plt.figure(figsize=(10,10))\n",
        "scatter = plt.scatter(x, y, c=y_test)\n",
        "plt.colorbar(scatter)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6_FQZG2IMYre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 잠재벡터 확인\n",
        "x = z_test_log_var[:, 0]\n",
        "y = z_test_log_var[:, 1]\n",
        "plt.figure(figsize=(10,10))\n",
        "scatter = plt.scatter(x, y, c=y_test)\n",
        "plt.colorbar(scatter)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "J2SGqfzHNSzU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}